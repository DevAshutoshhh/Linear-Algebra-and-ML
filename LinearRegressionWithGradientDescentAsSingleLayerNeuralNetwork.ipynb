{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a48aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb84bacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of data points and features\n",
    "n_samples = 100\n",
    "n_features = 4  # Change this value to test with more features\n",
    "\n",
    "# Generate random data for linear regression: y = 3*x + 4 + noise\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "true_weights = np.array([3] * n_features).reshape(-1, 1)\n",
    "true_bias = 4\n",
    "y = X @ true_weights + true_bias + np.random.randn(n_samples, 1) * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ec1975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment X with a column of ones for bias\n",
    "X_augmented = np.hstack([np.ones((n_samples, 1)), X])\n",
    "\n",
    "# Analytical solution for weights using the normal equation\n",
    "# w = (X^T * X)^(-1) * X^T * y\n",
    "start_time1 = time.time()\n",
    "w_analytical = np.linalg.inv(X_augmented.T @ X_augmented) @ X_augmented.T @ y\n",
    "y_pred_analytical = X_augmented @ w_analytical\n",
    "end_time1 = time.time()\n",
    "print(f\"Time taken by matrix inversion solution: {end_time1-start_time1} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6dfcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights and bias for the neural network\n",
    "weights = np.random.randn(n_features, 1)\n",
    "bias = np.random.randn(1)\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.01\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af7b277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass function\n",
    "def forward(X):\n",
    "    return X @ weights + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2689d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Mean Squared Error (MSE) loss\n",
    "def compute_loss(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dfd6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop (Gradient Descent)\n",
    "start_time2 = time.time()\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    y_pred = forward(X)\n",
    "\n",
    "    # Compute loss (for printing)\n",
    "    loss = compute_loss(y, y_pred)\n",
    "\n",
    "    \"\"\"\n",
    "    # Backpropagation (with direct calculation of gradient)\n",
    "    dL_dw = (2 / n_samples) * (X.T @ (y_pred - y))\n",
    "    dL_db = (2 / n_samples) * np.sum(y_pred - y)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Backpropagation with explicit chain rule\n",
    "    # Loss derivative w.r.t prediction (y_pred)\n",
    "    dL_dy_pred = -2 * (y - y_pred) / n_samples\n",
    "\n",
    "    # Prediction derivative w.r.t weights and bias\n",
    "    dL_dw = X.T @ dL_dy_pred  # Using chain rule on each term\n",
    "    dL_db = np.sum(dL_dy_pred)  # Sum over all samples for bias gradient\n",
    "    \n",
    "    # Update weights and bias\n",
    "    weights -= learning_rate * dL_dw\n",
    "    bias -= learning_rate * dL_db\n",
    "\n",
    "    # Print loss every 100 epochs (can be commented while comparing time taken by the two methods)\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {loss:.4f}')\n",
    "        \n",
    "end_time2 = time.time()\n",
    "print(f\"Time taken by neural network solution: {end_time2-start_time2} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5e7f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the trained neural network\n",
    "y_pred_nn = forward(X)\n",
    "\n",
    "\n",
    "# Compute errors for neural network and analytical solution\n",
    "nn_error = compute_loss(y, y_pred_nn)\n",
    "analytical_error = compute_loss(y, y_pred_analytical)\n",
    "\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nFinal Loss Comparison:\")\n",
    "print(f\"Neural Network Solution MSE: {nn_error:.4f}\")\n",
    "print(f\"Analytical Solution MSE: {analytical_error:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ba1326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results (for single feature)\n",
    "if n_features == 1:\n",
    "    plt.scatter(X, y, label='Original data')\n",
    "    plt.plot(X, y_pred_analytical, color='blue', label='Analytical solution')\n",
    "    plt.plot(X, y_pred_nn, color='red', linestyle='--', label='Neural Network fit')\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.title(\"Comparison of Analytical Solution and Neural Network Fit\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Plotting is available for single feature data only.\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2a85a446",
   "metadata": {},
   "source": [
    "EXERCISES:\n",
    "\n",
    "1. Demonstrate an example where the matrix inversion solution is slower than gradient descent.\n",
    "2. Demonstrate an example where the matrix inversion solution is slower than the neural network solution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
